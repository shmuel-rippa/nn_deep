{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation tips\n",
    "\n",
    "* Create Anaconda virtual environment with ipython notebook support\n",
    "  > conda create -n tf ipython-notebook --yes\n",
    "* The set up as explained in the [official site](https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#anaconda-installation) failed for me. Something to do with failure to update setup tools. The remedy was doing as explained in [here](https://github.com/ContinuumIO/anaconda-issues/issues/542): \n",
    " > pip install --ignore-installed --upgrade pip setuptools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hellow TensorFlow\n",
    "\n",
    "For the [O'reilly post](https://www.oreilly.com/learning/hello-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations in graph \n",
      "===========================\n",
      "x\n",
      "w/initial_value\n",
      "w\n",
      "w/Assign\n",
      "w/read\n",
      "y\n",
      "y_train\n",
      "sub\n",
      "pow/y\n",
      "pow\n",
      "\n",
      "Laste operation in graph is :  pow\n",
      "\n",
      "Inputs:\n",
      "===========  \n",
      "   Tensor(\"sub:0\", shape=(), dtype=float32)\n",
      "   Tensor(\"pow/y:0\", shape=(), dtype=float32)\n",
      "\n",
      "Outputs:\n",
      "===========  \n",
      "   Tensor(\"pow:0\", shape=(), dtype=float32)\n",
      "\n",
      "Operations in graph \n",
      "===========================\n",
      "x\n",
      "w/initial_value\n",
      "w\n",
      "w/Assign\n",
      "w/read\n",
      "y\n",
      "y_train\n",
      "sub\n",
      "pow/y\n",
      "pow\n",
      "gradients/Shape\n",
      "gradients/Const\n",
      "gradients/Fill\n",
      "gradients/pow_grad/Shape\n",
      "gradients/pow_grad/Shape_1\n",
      "gradients/pow_grad/BroadcastGradientArgs\n",
      "gradients/pow_grad/mul\n",
      "gradients/pow_grad/sub/y\n",
      "gradients/pow_grad/sub\n",
      "gradients/pow_grad/Pow\n",
      "gradients/pow_grad/mul_1\n",
      "gradients/pow_grad/Sum\n",
      "gradients/pow_grad/Reshape\n",
      "gradients/pow_grad/mul_2\n",
      "gradients/pow_grad/Log\n",
      "gradients/pow_grad/mul_3\n",
      "gradients/pow_grad/Sum_1\n",
      "gradients/pow_grad/Reshape_1\n",
      "gradients/pow_grad/tuple/group_deps\n",
      "gradients/pow_grad/tuple/control_dependency\n",
      "gradients/pow_grad/tuple/control_dependency_1\n",
      "gradients/sub_grad/Shape\n",
      "gradients/sub_grad/Shape_1\n",
      "gradients/sub_grad/BroadcastGradientArgs\n",
      "gradients/sub_grad/Sum\n",
      "gradients/sub_grad/Reshape\n",
      "gradients/sub_grad/Sum_1\n",
      "gradients/sub_grad/Neg\n",
      "gradients/sub_grad/Reshape_1\n",
      "gradients/sub_grad/tuple/group_deps\n",
      "gradients/sub_grad/tuple/control_dependency\n",
      "gradients/sub_grad/tuple/control_dependency_1\n",
      "gradients/y_grad/Shape\n",
      "gradients/y_grad/Shape_1\n",
      "gradients/y_grad/BroadcastGradientArgs\n",
      "gradients/y_grad/mul\n",
      "gradients/y_grad/Sum\n",
      "gradients/y_grad/Reshape\n",
      "gradients/y_grad/mul_1\n",
      "gradients/y_grad/Sum_1\n",
      "gradients/y_grad/Reshape_1\n",
      "gradients/y_grad/tuple/group_deps\n",
      "gradients/y_grad/tuple/control_dependency\n",
      "gradients/y_grad/tuple/control_dependency_1\n",
      "\n",
      "Laste operation in graph is :  gradients/y_grad/tuple/control_dependency_1\n",
      "\n",
      "Inputs:\n",
      "===========  \n",
      "   Tensor(\"gradients/y_grad/Reshape_1:0\", shape=(), dtype=float32)\n",
      "\n",
      "Outputs:\n",
      "===========  \n",
      "   Tensor(\"gradients/y_grad/tuple/control_dependency_1:0\", shape=(), dtype=float32)\n",
      "\n",
      "Laste operation in graph is now:  init\n",
      "\n",
      "Create a session to evaluate graph operations\n",
      "===============================================\n",
      "Run session to obtaine the value of x:  1.0\n",
      "Run session to obtaine the value of y:  0.8\n",
      "Initial value of loss function       :  0.64\n",
      "\n",
      "Compute gradients:                    1.6\n",
      "\n",
      "Updates weights after one BackProp step: 0.759999990463, loss function=0.577600002289\n",
      "\n",
      "\n",
      "   0 : Weight=0.722, loss=0.5213\n",
      "  10 : Weight=0.432, loss=0.1869\n",
      "  20 : Weight=0.259, loss=0.06699\n",
      "  30 : Weight=0.155, loss=0.02402\n",
      "  40 : Weight=0.0928, loss=0.008609\n",
      "  50 : Weight=0.0556, loss=0.003086\n",
      "  60 : Weight=0.0333, loss=0.001106\n",
      "  70 : Weight=0.0199, loss=0.0003966\n",
      "  80 : Weight=0.0119, loss=0.0001422\n",
      "  90 : Weight=0.00714, loss=5.097e-05\n",
      " 100 : Weight=0.00427, loss=1.827e-05\n",
      " 110 : Weight=0.00256, loss=6.55e-06\n",
      " 120 : Weight=0.00153, loss=2.348e-06\n",
      " 130 : Weight=0.000917, loss=8.418e-07\n",
      " 140 : Weight=0.000549, loss=3.018e-07\n",
      " 150 : Weight=0.000329, loss=1.082e-07\n",
      " 160 : Weight=0.000197, loss=3.878e-08\n",
      " 170 : Weight=0.000118, loss=1.39e-08\n",
      " 180 : Weight=7.06e-05, loss=4.984e-09\n",
      " 190 : Weight=4.23e-05, loss=1.787e-09\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "\n",
    "ops.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "graph.get_operations()\n",
    "\n",
    "# Model of a simple neuron: y <-- x * w\n",
    "x       = tf.constant(1.0,name='x')\n",
    "w       = tf.Variable(0.8,name='w')\n",
    "y       = tf.mul(w , x, name='y')\n",
    "\n",
    "y_     = tf.constant(0.0,name='y_train')\n",
    "loss   = (y-y_)**2\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Print the nodes of teh graph, also called 'operations' or 'ops'\n",
    "#--------------------------------------------------------------\n",
    "print 'Operations in graph \\n==========================='\n",
    "for op in graph.get_operations():\n",
    "    print op.name\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Get the last operation (**2) \n",
    "#--------------------------------------------------------------\n",
    "op = graph.get_operations()[-1]\n",
    "print '\\nLaste operation in graph is : ',op.name\n",
    "print '\\nInputs:\\n===========  '\n",
    "for op_input in op.inputs: print '  ',op_input\n",
    "print '\\nOutputs:\\n===========  '\n",
    "for op_output in op.outputs: print '  ',op_output\n",
    "    \n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Define gradient descent optimizer\n",
    "#--------------------------------------------------------------\n",
    "optim          = tf.train.GradientDescentOptimizer(learning_rate=0.025)\n",
    "grads_and_vars = optim.compute_gradients(loss)\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# NOdes of graph after all operations related to GD are added\n",
    "#--------------------------------------------------------------\n",
    "print '\\nOperations in graph \\n==========================='\n",
    "for op in graph.get_operations():\n",
    "    print op.name\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Get the last operation and investigate it\n",
    "#--------------------------------------------------------------\n",
    "op = graph.get_operations()[-1]\n",
    "print '\\nLaste operation in graph is : ',op.name\n",
    "print '\\nInputs:\\n===========  '\n",
    "for op_input in op.inputs: print '  ',op_input\n",
    "print '\\nOutputs:\\n===========  '\n",
    "for op_output in op.outputs: print '  ',op_output\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Create an operation that initializes all variables in the graph\n",
    "#--------------------------------------------------------------\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "op = graph.get_operations()[-1]\n",
    "print '\\nLaste operation in graph is now: ',op.name\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "# Running the graph\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "print '\\nCreate a session to evaluate graph operations\\n==============================================='    \n",
    "sess = tf.Session()                      # For regular python code\n",
    "#sess  = tf.InteractiveSession(graph=graph) # for ipython notebook\n",
    "\n",
    "sess.run(init)\n",
    "print 'Run session to obtaine the value of x: ',sess.run(x)\n",
    "print 'Run session to obtaine the value of y: ',sess.run(y)\n",
    "print 'Initial value of loss function       : ',sess.run(loss)\n",
    "\n",
    "\n",
    "print '\\nCompute gradients:                   ', sess.run(grads_and_vars[0][0])\n",
    "\n",
    "sess.run(optim.apply_gradients(grads_and_vars))\n",
    "print '\\nUpdates weights after one BackProp step: {0}, loss function={1}'.format(sess.run(w),sess.run(loss))\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Full training step: compute gradients and apply them\n",
    "#--------------------------------------------------------------\n",
    "train_step = tf.train.GradientDescentOptimizer(0.025).minimize(loss)\n",
    "print '\\n'\n",
    "for i in range(200):\n",
    "    sess.run(train_step)\n",
    "    if not i%10:\n",
    "        print '{0:4} : Weight={1:5.3}, loss={2:6.4}'.format(i,sess.run(w),sess.run(loss))\n",
    "\n",
    "\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and visualization\n",
    "\n",
    "To  see the graphs invoke the command:\n",
    "> tensorboard --logdir=log_simple_stat\n",
    "\n",
    "which can then be viewed in the browser at\n",
    "> localhost:6006/#events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant(1.0, name='input')\n",
    "w = tf.Variable(0.8, name='weight')\n",
    "y = tf.mul(w, x, name='output')\n",
    "y_ = tf.constant(0.0, name='correct_value')\n",
    "loss = tf.pow(y - y_, 2, name='loss')\n",
    "train_step = tf.train.GradientDescentOptimizer(0.025).minimize(loss)\n",
    "\n",
    "for value in [x, w, y, y_, loss]:\n",
    "    tf.scalar_summary(value.op.name, value)\n",
    "\n",
    "summaries = tf.merge_all_summaries()\n",
    "\n",
    "sess = tf.Session()\n",
    "summary_writer = tf.train.SummaryWriter('log_simple_stats', sess.graph)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(100):\n",
    "    summary_writer.add_summary(sess.run(summaries), i)\n",
    "    sess.run(train_step)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
